{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules to be imported \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations \n",
    "from random import seed\n",
    "from random import randint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_k(x,k):\n",
    "    return 1 / (1 + k*np.exp(-z))\n",
    "\n",
    "def relu(x):\n",
    "    return np.log(1+np.exp(x))\n",
    "\n",
    "def drelu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def loss(out,Y):\n",
    "        loss = (-1)*(np.sum(np.multiply(np.log(out), Y) + np.multiply((1 - Y), np.log(1 - out))))/(Y.shape[1])\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(X,Y,learning_rate):\n",
    "    #taking all 9 layers as input\n",
    "    in_layer_no=X.shape[0] #no of attributes\n",
    "    hid_layer_no=int(2/3*in_layer_no)\n",
    "    out_layer_no=1\n",
    "\n",
    "    #initial weights\n",
    "    wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "    bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "    w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "    b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "    initial_weights=[wh,bh,w_out,b_out]\n",
    "    dwh_old=0\n",
    "    dw_out_old=0\n",
    "    for i in range(0,75000):\n",
    "        #forward propogation\n",
    "        #input to hidden layer = dot product(X,wh) + bh\n",
    "        hid_layer_input = np.dot(wh,X) + bh\n",
    "        hid_layer_act = relu(hid_layer_input)\n",
    "        \n",
    "        # Final output layer prediction\n",
    "        out_layer_input = np.dot(w_out,hid_layer_act) + b_out\n",
    "        out_layer_act = sigmoid(out_layer_input)\n",
    "        lo=loss(out_layer_act,Y)\n",
    "        if(i%1000==0):\n",
    "            print(i,lo)\n",
    "        '''dZ2 = out_layer_act - Y\n",
    "        dW2 = (1 /X.shape[1]) * np.dot(dZ2, hid_layer_act.T)\n",
    "        db2 = (1 / X.shape[1]) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.multiply(np.dot(w_out.T, dZ2), 1 - np.power(hid_layer_act, 2))\n",
    "        dW1 = (1 / X.shape[1]) * np.dot(dZ1, X.T)\n",
    "        db1 = (1 / X.shape[1]) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dW1\n",
    "        w_out = w_out - learning_rate * dW2\n",
    "        bh = bh - learning_rate * db1\n",
    "        b_out = b_out - learning_rate * db2\n",
    "        '''\n",
    "        #backward propogation output layer    \n",
    "        t_o = out_layer_act - Y\n",
    "        sigmak = t_o * sigmoid(out_layer_input)*(1-sigmoid(out_layer_input))   \n",
    "        dLoss_W2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak,hid_layer_act.T)\n",
    "        dLoss_b2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak, np.ones([sigmak.shape[1],1])) \n",
    "          \n",
    "        #backward propogation input layer\n",
    "        dLoss_A1 = np.dot(w_out.T,sigmak)\n",
    "        dLoss_Z1 = dLoss_A1 * drelu(hid_layer_input)        \n",
    "        dLoss_A0 = np.dot(wh.T,dLoss_Z1)\n",
    "        dLoss_W1 = 1/X.shape[1] * np.dot(dLoss_Z1,X.T)\n",
    "        dLoss_b1 = 1/X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n",
    "        \n",
    "        wh = wh - learning_rate * dLoss_W1\n",
    "        w_out = w_out - learning_rate * dLoss_W2\n",
    "        bh = bh - learning_rate * dLoss_b1\n",
    "        b_out = b_out - learning_rate * dLoss_b2\n",
    "    return [wh,bh,w_out,b_out]\n",
    "    ''' \n",
    "        #backpropogation\n",
    "        dout_layer_act = (out_layer_act - Y) / (out_layer_act * (1 - out_layer_act))\n",
    "        dZ2 = np.multiply(dout_layer_act, out_layer_act * (1 - out_layer_act))\n",
    "        dw_out = np.dot(dZ2, hid_layer_act.T)\n",
    "        #dw_out=dw_out+0.5*dw_out_old\n",
    "        #dw_out_old=dw_out\n",
    "        db_out = np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dhid_layer_act = np.dot(w_out.T, dZ2)\n",
    "        dZ1 = np.multiply(dhid_layer_act, dhid_layer_act * (1 - dhid_layer_act))\n",
    "        dwh = np.dot(dZ1, X.T)\n",
    "        #dwh=dwh+0.2*dwh_old\n",
    "        #dwh_old=dwh\n",
    "        dbh = np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dwh\n",
    "        w_out = w_out - learning_rate * dw_out\n",
    "        bh = bh - learning_rate * dbh\n",
    "        b_out = b_out - learning_rate * db_out\n",
    "    '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final forward propogation to test trained model \n",
    "def predict(XTrain,YTrain,XTest,YTest,learning_rate):\n",
    "    final_weights=ann(XTrain,YTrain,learning_rate)\n",
    "    hid_layer_input = np.dot(final_weights[0],XTest) + final_weights[1]\n",
    "    hid_layer_act = relu(hid_layer_input)\n",
    "    out_layer_input = np.dot(final_weights[2],hid_layer_act) + final_weights[3]\n",
    "    out_layer_act = sigmoid(out_layer_input)\n",
    "    predictions = out_layer_act > 0.5\n",
    "    predictions=predictions.astype(int)  \n",
    "    accuracy=float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100)\n",
    "    #print(accuracy)\n",
    "    #print ('Accuracy: %f' % float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100) + '%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(X,Y):\n",
    "    #print(X.shape,Y.shape)\n",
    "    XTrain,XTest,YTrain,YTest=train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "    X,Y=X.to_numpy(),Y.to_numpy()\n",
    "    XTrain,XTest,YTrain,YTest= XTrain.to_numpy().T,XTest.to_numpy().T,YTrain.to_numpy().reshape(1, YTrain.shape[0]),YTest.to_numpy().reshape(1, YTest.shape[0])\n",
    "    X,Y=X.T,Y.reshape(1, Y.shape[0])\n",
    "    #print(X.shape,Y.shape,XTrain.shape,YTrain.shape,XTest.shape,YTest.shape)\n",
    "    acc=predict(XTrain,YTrain,XTest,YTest,0.05)\n",
    "    return(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create all possible combination of subsets of size r\n",
    "def rSubset(arr,r): \n",
    "    return list(combinations(arr, r)) \n",
    "def comb(r):\n",
    "    arr = [2,3,4,5,6,7,8,9,10] \n",
    "    return(rSubset(arr, r))\n",
    "\n",
    "#function for bagging of attributes \n",
    "def attribute_bagging(r):\n",
    "    s=comb(r)\n",
    "    #print(s,len(s))\n",
    "    length=len(s)\n",
    "    avg=[]\n",
    "    #repeat 5 times\n",
    "    for i in range(0,5):\n",
    "        #9 random values\n",
    "        #generating 9 random values with range given as the 0,number of combination\n",
    "        rand_index=random.sample(range(0, length), 9)\n",
    "        l=[]\n",
    "        for j in rand_index:\n",
    "            t=s[j]\n",
    "            #subsetting the dataframe X based on rand_index values\n",
    "            new_dataset = X.loc[:,list(t)]\n",
    "            #sending the new dataframe to the ann function \n",
    "            acc=split_test_train(new_dataset,Y)\n",
    "            #saving accuracy of each accuracy in a list\n",
    "            l.append(acc)\n",
    "        #finding average of accuracies of each iteration\n",
    "        avg1=sum(l)/len(l) \n",
    "        avg.append(avg1)\n",
    "    return(avg)\n",
    "            \n",
    "    \n",
    "    \n",
    "def ANN_att_bag():\n",
    "    total=[]\n",
    "    #attribute bagging for subset size 2,3,4,5,6,7,8 and 9 each time\n",
    "    for i in range(2,10):\n",
    "        #append accuracies of each subset size\n",
    "        total.append(attribute_bagging(i))\n",
    "    max_avg=[]\n",
    "    #taking max of accuracies for each subset size \n",
    "    for i in total:\n",
    "        max_avg.append(max(i))\n",
    "    #print(max_avg)\n",
    "    #plot to show accuracies for each subset \n",
    "    keys=[2,3,4,5,6,7,8,9]\n",
    "    #converting to a dictionary\n",
    "    dictionary = dict(zip(keys, max_avg))\n",
    "    print(dictionary)\n",
    "    #p\n",
    "    plt.plot(*zip(*sorted(dictionary.items())))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #reading preprocessed dataset\n",
    "    df_proc = pd.read_csv(\"preprocessed.csv\") \n",
    "    df_proc.columns=[0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "    #finding X(attributes excluding Target) and Y(Target)\n",
    "    Y = df_proc.filter([11], axis=1)\n",
    "    X = df_proc.drop([0,1,11],axis=1)\n",
    "    #ANN \n",
    "    ANN_att_bag()\n",
    "    #RANDOM FOREST\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
