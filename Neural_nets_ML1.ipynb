{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_k(x,k):\n",
    "    return 1 / (1 + k*np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_layer_act\n",
    "def drelu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(out,Y):\n",
    "        loss = (-1)*(np.sum(np.multiply(np.log(out), Y) + np.multiply((1 - Y), np.log(1 - out))))/(Y.shape[1])\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testimg relu and sigmoid\n",
    "#relu(5)\n",
    "#relu(-3)\n",
    "#relu(0)\n",
    "\n",
    "#sigmoid(5)\n",
    "#sigmoid(0)\n",
    "#sigmoid(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = pd.read_csv(\"preprocessed.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.columns=[\"sl_no\",\"id\",\"thickness\", \"cellsize\", \"cellshape\", \"madhesion\", \"secellsize\", \"barenuclei\", \"chromatin\", \"nucleoli\", \"mitosis\",\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_proc.filter(['Class'], axis=1)\n",
    "X = df_proc.drop(['sl_no','id','Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699) (9, 559) (1, 559) (9, 140) (1, 140)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "XTrain,XTest,YTrain,YTest=train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X,Y=X.to_numpy(),Y.to_numpy()\n",
    "XTrain,XTest,YTrain,YTest= XTrain.to_numpy().T,XTest.to_numpy().T,YTrain.to_numpy().reshape(1, YTrain.shape[0]),YTest.to_numpy().reshape(1, YTest.shape[0])\n",
    "X,Y=X.T,Y.reshape(1, Y.shape[0])\n",
    "\n",
    "print(X.shape,Y.shape,XTrain.shape,YTrain.shape,XTest.shape,YTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking all 9 layers as input\n",
    "in_layer_no=X.shape[0] #no of attributes\n",
    "hid_layer_no=int(1.5*in_layer_no)\n",
    "out_layer_no=1\n",
    "\n",
    "#initial weights\n",
    "wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "initial_weights=[wh,bh,w_out,b_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "13\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(in_layer_no)\n",
    "print(hid_layer_no)\n",
    "print(out_layer_no)\n",
    "wh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(X,Y,learning_rate):\n",
    "    #taking all 9 layers as input\n",
    "    in_layer_no=X.shape[0] #no of attributes\n",
    "    hid_layer_no=int(1.5*in_layer_no)\n",
    "    out_layer_no=1\n",
    "\n",
    "    #initial weights\n",
    "    wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "    bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "    w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "    b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "    initial_weights=[wh,bh,w_out,b_out]\n",
    "    dwh_old=0\n",
    "    dw_out_old=0\n",
    "    for i in range(0,100000):\n",
    "        #forward propogation\n",
    "        #input to hidden layer = dot product(X,wh) + bh\n",
    "        hid_layer_input = np.dot(wh,X) + bh\n",
    "        hid_layer_act = relu(hid_layer_input)\n",
    "        \n",
    "        # Final output layer prediction\n",
    "        out_layer_input = np.dot(w_out,hid_layer_act) + b_out\n",
    "        out_layer_act = sigmoid(out_layer_input)\n",
    "        lo=loss(out_layer_act,Y)\n",
    "        if(i%1000==0):\n",
    "            print(i,lo)\n",
    "        '''dZ2 = out_layer_act - Y\n",
    "        dW2 = (1 /X.shape[1]) * np.dot(dZ2, hid_layer_act.T)\n",
    "        db2 = (1 / X.shape[1]) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.multiply(np.dot(w_out.T, dZ2), 1 - np.power(hid_layer_act, 2))\n",
    "        dW1 = (1 / X.shape[1]) * np.dot(dZ1, X.T)\n",
    "        db1 = (1 / X.shape[1]) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dW1\n",
    "        w_out = w_out - learning_rate * dW2\n",
    "        bh = bh - learning_rate * db1\n",
    "        b_out = b_out - learning_rate * db2\n",
    "        '''\n",
    "        #backward propogation output layer    \n",
    "        t_o = out_layer_act - Y\n",
    "        sigmak = t_o * sigmoid(out_layer_input)*(1-sigmoid(out_layer_input))   \n",
    "        dLoss_W2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak,hid_layer_act.T)\n",
    "        dLoss_b2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak, np.ones([sigmak.shape[1],1])) \n",
    "          \n",
    "        #backward propogation input layer\n",
    "        dLoss_A1 = np.dot(w_out.T,sigmak)\n",
    "        dLoss_Z1 = dLoss_A1 * drelu(hid_layer_input)        \n",
    "        dLoss_A0 = np.dot(wh.T,dLoss_Z1)\n",
    "        dLoss_W1 = 1/X.shape[1] * np.dot(dLoss_Z1,X.T)\n",
    "        dLoss_b1 = 1/X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n",
    "        \n",
    "        wh = wh - learning_rate * dLoss_W1\n",
    "        w_out = w_out - learning_rate * dLoss_W2\n",
    "        bh = bh - learning_rate * dLoss_b1\n",
    "        b_out = b_out - learning_rate * dLoss_b2\n",
    "    return [wh,bh,w_out,b_out]\n",
    "    ''' \n",
    "        #backpropogation\n",
    "        dout_layer_act = (out_layer_act - Y) / (out_layer_act * (1 - out_layer_act))\n",
    "        dZ2 = np.multiply(dout_layer_act, out_layer_act * (1 - out_layer_act))\n",
    "        dw_out = np.dot(dZ2, hid_layer_act.T)\n",
    "        #dw_out=dw_out+0.5*dw_out_old\n",
    "        #dw_out_old=dw_out\n",
    "        db_out = np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dhid_layer_act = np.dot(w_out.T, dZ2)\n",
    "        dZ1 = np.multiply(dhid_layer_act, dhid_layer_act * (1 - dhid_layer_act))\n",
    "        dwh = np.dot(dZ1, X.T)\n",
    "        #dwh=dwh+0.2*dwh_old\n",
    "        #dwh_old=dwh\n",
    "        dbh = np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dwh\n",
    "        w_out = w_out - learning_rate * dw_out\n",
    "        bh = bh - learning_rate * dbh\n",
    "        b_out = b_out - learning_rate * db_out\n",
    "    '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6955585535760341\n",
      "1000 0.6416857443134771\n",
      "2000 0.6152604919188736\n",
      "3000 0.34729218104070037\n",
      "4000 0.1601130042463964\n",
      "5000 0.12858983775051483\n",
      "6000 0.11632477430357155\n",
      "7000 0.10986795228182548\n",
      "8000 0.1054817054329029\n",
      "9000 0.10241219731315525\n",
      "10000 0.10020311581639349\n",
      "11000 0.09851794212354653\n",
      "12000 0.09727610716456002\n",
      "13000 0.09618172491524497\n",
      "14000 0.09504198533227969\n",
      "15000 0.09398119853243955\n",
      "16000 0.09330727605065818\n",
      "17000 0.09264497192229282\n",
      "18000 0.09214707059213088\n",
      "19000 0.09171271751994071\n",
      "20000 0.09127701317780025\n",
      "21000 0.0909387608032861\n",
      "22000 0.09063385270339681\n",
      "23000 0.09033048607155239\n",
      "24000 0.09008182899623522\n",
      "25000 0.08986705847237657\n",
      "26000 0.0896740211774491\n",
      "27000 0.08949991956376019\n",
      "28000 0.08934248534479683\n",
      "29000 0.08920004290502738\n",
      "30000 0.08907086577022913\n",
      "31000 0.08895316976592393\n",
      "32000 0.0888463708958416\n",
      "33000 0.08874859188011655\n",
      "34000 0.08865923105850672\n",
      "35000 0.08857953194874174\n",
      "36000 0.08850838445814893\n",
      "37000 0.08844044469582218\n",
      "38000 0.08837261881007151\n",
      "39000 0.08830342665366285\n",
      "40000 0.08833298978286673\n",
      "41000 0.08821278345337909\n",
      "42000 0.08802868355683678\n",
      "43000 0.08795305705671841\n",
      "44000 0.0878954008842834\n",
      "45000 0.08784180086060366\n",
      "46000 0.08779097134729971\n",
      "47000 0.08774559395153998\n",
      "48000 0.08769364970705056\n",
      "49000 0.08765878499999834\n",
      "50000 0.0876268412723174\n",
      "51000 0.08759562733421776\n",
      "52000 0.0875641434654773\n",
      "53000 0.08753217568779292\n",
      "54000 0.08750052732213774\n",
      "55000 0.08746935268551846\n",
      "56000 0.08743765891684788\n",
      "57000 0.08740435675057584\n",
      "58000 0.08737085282090104\n",
      "59000 0.08733646736449699\n",
      "60000 0.08730100488971691\n",
      "61000 0.08726507659401257\n",
      "62000 0.08722800344074509\n",
      "63000 0.08716309856466253\n",
      "64000 0.08712286837905014\n",
      "65000 0.08708033122847537\n",
      "66000 0.0870358255052983\n",
      "67000 0.08699061167838774\n",
      "68000 0.08694510588778694\n",
      "69000 0.08690022307865344\n",
      "70000 0.08685607270825879\n",
      "71000 0.08681236008491215\n",
      "72000 0.08676936337634843\n",
      "73000 0.08672670169871521\n",
      "74000 0.08668545641506159\n",
      "75000 0.0866449484982509\n",
      "76000 0.0866053379385929\n",
      "77000 0.08656660786286527\n",
      "78000 0.08652855563288157\n",
      "79000 0.08649097787503258\n",
      "80000 0.08645472675505401\n",
      "81000 0.08641898616552177\n",
      "82000 0.0863844602015874\n",
      "83000 0.08635017169908223\n",
      "84000 0.08631722279160794\n",
      "85000 0.08628496453909815\n",
      "86000 0.08625362937220843\n",
      "87000 0.0862233921999874\n",
      "88000 0.08619413498098004\n",
      "89000 0.08616578641761174\n",
      "90000 0.08613795606592305\n",
      "91000 0.08611094313482633\n",
      "92000 0.08608513995338987\n",
      "93000 0.08605903270098578\n",
      "94000 0.08603382383995721\n",
      "95000 0.0860098226383356\n",
      "96000 0.08598623995531605\n",
      "97000 0.08596307186896829\n",
      "98000 0.08594031913425015\n",
      "99000 0.08591800287486005\n"
     ]
    }
   ],
   "source": [
    "#here replace X with X train and Y with Y train\n",
    "final_weights=ann(XTrain,YTrain,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final forward propogation to test trained model \n",
    "def predict(final_weights,XTest,YTest):\n",
    "    hid_layer_input = np.dot(final_weights[0],XTest) + final_weights[1]\n",
    "    hid_layer_act = relu(hid_layer_input)\n",
    "    out_layer_input = np.dot(final_weights[2],hid_layer_act) + final_weights[3]\n",
    "    out_layer_act = sigmoid(out_layer_input)\n",
    "    predictions = out_layer_act > 0.5\n",
    "    predictions=predictions.astype(int)  \n",
    "    accuracy=float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100)\n",
    "    #print(accuracy)\n",
    "    #print ('Accuracy: %f' % float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100) + '%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=predict(final_weights,XTest,YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
