{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_k(x,k):\n",
    "    return 1 / (1 + k*np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_layer_act\n",
    "def drelu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(out,Y):\n",
    "        loss = (-1)*(np.sum(np.multiply(np.log(out), Y) + np.multiply((1 - Y), np.log(1 - out))))/(Y.shape[1])\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testimg relu and sigmoid\n",
    "#relu(5)\n",
    "#relu(-3)\n",
    "#relu(0)\n",
    "\n",
    "#sigmoid(5)\n",
    "#sigmoid(0)\n",
    "#sigmoid(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = pd.read_csv(\"preprocessed.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.columns=[\"sl_no\",\"id\",\"thickness\", \"cellsize\", \"cellshape\", \"madhesion\", \"secellsize\", \"barenuclei\", \"chromatin\", \"nucleoli\", \"mitosis\",\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_proc.filter(['Class'], axis=1)\n",
    "X = df_proc.drop(['sl_no','id','Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699) (9, 559) (1, 559) (9, 140) (1, 140)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "XTrain,XTest,YTrain,YTest=train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X,Y=X.to_numpy(),Y.to_numpy()\n",
    "XTrain,XTest,YTrain,YTest= XTrain.to_numpy().T,XTest.to_numpy().T,YTrain.to_numpy().reshape(1, YTrain.shape[0]),YTest.to_numpy().reshape(1, YTest.shape[0])\n",
    "X,Y=X.T,Y.reshape(1, Y.shape[0])\n",
    "\n",
    "print(X.shape,Y.shape,XTrain.shape,YTrain.shape,XTest.shape,YTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking all 9 layers as input\n",
    "in_layer_no=X.shape[0] #no of attributes\n",
    "hid_layer_no=int(1.5*in_layer_no)\n",
    "out_layer_no=1\n",
    "\n",
    "#initial weights\n",
    "wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "initial_weights=[wh,bh,w_out,b_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "13\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(in_layer_no)\n",
    "print(hid_layer_no)\n",
    "print(out_layer_no)\n",
    "wh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(X,Y,learning_rate,initial_weights):\n",
    "    wh=initial_weights[0]\n",
    "    bh=initial_weights[1]\n",
    "    w_out=initial_weights[2]\n",
    "    b_out=initial_weights[3]\n",
    "    dwh_old=0\n",
    "    dw_out_old=0\n",
    "    for i in range(0,100000):\n",
    "        #forward propogation\n",
    "        #input to hidden layer = dot product(X,wh) + bh\n",
    "        hid_layer_input = np.dot(wh,X) + bh\n",
    "        hid_layer_act = relu(hid_layer_input)\n",
    "        \n",
    "        # Final output layer prediction\n",
    "        out_layer_input = np.dot(w_out,hid_layer_act) + b_out\n",
    "        out_layer_act = sigmoid(out_layer_input)\n",
    "        lo=loss(out_layer_act,Y)\n",
    "        if(i%1000==0):\n",
    "            print(i,lo)\n",
    "        '''dZ2 = out_layer_act - Y\n",
    "        dW2 = (1 /X.shape[1]) * np.dot(dZ2, hid_layer_act.T)\n",
    "        db2 = (1 / X.shape[1]) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.multiply(np.dot(w_out.T, dZ2), 1 - np.power(hid_layer_act, 2))\n",
    "        dW1 = (1 / X.shape[1]) * np.dot(dZ1, X.T)\n",
    "        db1 = (1 / X.shape[1]) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dW1\n",
    "        w_out = w_out - learning_rate * dW2\n",
    "        bh = bh - learning_rate * db1\n",
    "        b_out = b_out - learning_rate * db2\n",
    "        '''\n",
    "        #backward propogation output layer    \n",
    "        t_o = out_layer_act - Y\n",
    "        sigmak = t_o * sigmoid(out_layer_input)*(1-sigmoid(out_layer_input))   \n",
    "        dLoss_W2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak,hid_layer_act.T)\n",
    "        dLoss_b2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak, np.ones([sigmak.shape[1],1])) \n",
    "          \n",
    "        #backward propogation input layer\n",
    "        dLoss_A1 = np.dot(w_out.T,sigmak)\n",
    "        dLoss_Z1 = dLoss_A1 * drelu(hid_layer_input)        \n",
    "        dLoss_A0 = np.dot(wh.T,dLoss_Z1)\n",
    "        dLoss_W1 = 1/X.shape[1] * np.dot(dLoss_Z1,X.T)\n",
    "        dLoss_b1 = 1/X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n",
    "        \n",
    "        wh = wh - learning_rate * dLoss_W1\n",
    "        w_out = w_out - learning_rate * dLoss_W2\n",
    "        bh = bh - learning_rate * dLoss_b1\n",
    "        b_out = b_out - learning_rate * dLoss_b2\n",
    "    return [wh,bh,w_out,b_out]\n",
    "    ''' \n",
    "        #backpropogation\n",
    "        dout_layer_act = (out_layer_act - Y) / (out_layer_act * (1 - out_layer_act))\n",
    "        dZ2 = np.multiply(dout_layer_act, out_layer_act * (1 - out_layer_act))\n",
    "        dw_out = np.dot(dZ2, hid_layer_act.T)\n",
    "        #dw_out=dw_out+0.5*dw_out_old\n",
    "        #dw_out_old=dw_out\n",
    "        db_out = np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dhid_layer_act = np.dot(w_out.T, dZ2)\n",
    "        dZ1 = np.multiply(dhid_layer_act, dhid_layer_act * (1 - dhid_layer_act))\n",
    "        dwh = np.dot(dZ1, X.T)\n",
    "        #dwh=dwh+0.2*dwh_old\n",
    "        #dwh_old=dwh\n",
    "        dbh = np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dwh\n",
    "        w_out = w_out - learning_rate * dw_out\n",
    "        bh = bh - learning_rate * dbh\n",
    "        b_out = b_out - learning_rate * db_out\n",
    "    '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6924870324766284\n",
      "1000 0.6409882314766514\n",
      "2000 0.6151574354159735\n",
      "3000 0.37620229493097357\n",
      "4000 0.16523924342351295\n",
      "5000 0.13070333387747668\n",
      "6000 0.11757881827467052\n",
      "7000 0.11074195930597147\n",
      "8000 0.10614072969902945\n",
      "9000 0.10293803471741805\n",
      "10000 0.10062520368964491\n",
      "11000 0.09888694964328046\n",
      "12000 0.09757093015515572\n",
      "13000 0.09640685524804601\n",
      "14000 0.09527991046746233\n",
      "15000 0.09420178793595603\n",
      "16000 0.09351784879340287\n",
      "17000 0.09285779115516751\n",
      "18000 0.09235957553809906\n",
      "19000 0.0918832281090563\n",
      "20000 0.0914741684964683\n",
      "21000 0.09109619477998651\n",
      "22000 0.09079129886220294\n",
      "23000 0.09050179564560157\n",
      "24000 0.09024006755067336\n",
      "25000 0.0900175844229905\n",
      "26000 0.08982628171646727\n",
      "27000 0.08965155915995127\n",
      "28000 0.08949346043327842\n",
      "29000 0.0893493021199282\n",
      "30000 0.08921826819064889\n",
      "31000 0.08909867946532049\n",
      "32000 0.0889891698944233\n",
      "33000 0.0888889655583273\n",
      "34000 0.08879696664414322\n",
      "35000 0.08871224083038855\n",
      "36000 0.08863415932403042\n",
      "37000 0.08856308723642567\n",
      "38000 0.08849939256724416\n",
      "39000 0.08843865718528028\n",
      "40000 0.08837840644235356\n",
      "41000 0.08830747856883744\n",
      "42000 0.0882517830362967\n",
      "43000 0.08825510802422325\n",
      "44000 0.08803944010257442\n",
      "45000 0.08797380105565786\n",
      "46000 0.08790222537365532\n",
      "47000 0.08783641906722581\n",
      "48000 0.08778182538736716\n",
      "49000 0.08773141301453519\n",
      "50000 0.0876778667651708\n",
      "51000 0.08762439534250901\n",
      "52000 0.08758465963137811\n",
      "53000 0.08754900035324215\n",
      "54000 0.08751396910522592\n",
      "55000 0.08748021428654985\n",
      "56000 0.08744785560998541\n",
      "57000 0.0874174323678076\n",
      "58000 0.08739260449233471\n",
      "59000 0.08736493757622113\n",
      "60000 0.08733654140165586\n",
      "61000 0.087307208456088\n",
      "62000 0.0872770551622873\n",
      "63000 0.08724497168862044\n",
      "64000 0.08721120865116924\n",
      "65000 0.08717627422461806\n",
      "66000 0.08715197495133666\n",
      "67000 0.08710369729167428\n",
      "68000 0.08706529289832238\n",
      "69000 0.08702951157823727\n",
      "70000 0.0869780962861623\n",
      "71000 0.08694081279297206\n",
      "72000 0.08690039710271025\n",
      "73000 0.08685335035552427\n",
      "74000 0.08679952284654571\n",
      "75000 0.0867466374912036\n",
      "76000 0.08668638359109973\n",
      "77000 0.08662702378502775\n",
      "78000 0.08657757751295658\n",
      "79000 0.08652968173750608\n",
      "80000 0.0864834559411885\n",
      "81000 0.08643848918469961\n",
      "82000 0.0863946454410793\n",
      "83000 0.08635169788018515\n",
      "84000 0.08631019784512164\n",
      "85000 0.0862691410377746\n",
      "86000 0.08622939316115533\n",
      "87000 0.08618741197164508\n",
      "88000 0.08614269923920781\n",
      "89000 0.08609969637375987\n",
      "90000 0.0860567163428354\n",
      "91000 0.08601658814098628\n",
      "92000 0.08597739924097858\n",
      "93000 0.08593894692090154\n",
      "94000 0.08590190041483514\n",
      "95000 0.085865258196293\n",
      "96000 0.08582909415828675\n",
      "97000 0.08579386004958339\n",
      "98000 0.0857589120717221\n",
      "99000 0.08572253097975255\n"
     ]
    }
   ],
   "source": [
    "#here replace X with X train and Y with Y train\n",
    "final_weights=ann(XTrain,YTrain,0.05,initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final backpropogation to test training data \n",
    "hid_layer_input = np.dot(final_weights[0],XTest) + final_weights[1]\n",
    "hid_layer_act = relu(hid_layer_input)\n",
    "out_layer_input = np.dot(final_weights[2],hid_layer_act) + final_weights[3]\n",
    "out_layer_act = sigmoid(out_layer_input)\n",
    "predictions = out_layer_act > 0.5\n",
    "predictions=predictions.astype(int)  \n",
    "\n",
    "#here replace the X with X test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97%\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: %d' % float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100) + '%')\n",
    "#replace Y with Y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
