{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_k(x,k):\n",
    "    return 1 / (1 + k*np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_layer_act\n",
    "def drelu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(out,Y):\n",
    "        loss = (-1)*(np.sum(np.multiply(np.log(out), Y) + np.multiply((1 - Y), np.log(1 - out))))/(Y.shape[1])\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testimg relu and sigmoid\n",
    "#relu(5)\n",
    "#relu(-3)\n",
    "#relu(0)\n",
    "\n",
    "#sigmoid(5)\n",
    "#sigmoid(0)\n",
    "#sigmoid(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = pd.read_csv(\"preprocessed.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.columns=[\"sl_no\",\"id\",\"thickness\", \"cellsize\", \"cellshape\", \"madhesion\", \"secellsize\", \"barenuclei\", \"chromatin\", \"nucleoli\", \"mitosis\",\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_proc.filter(['Class'], axis=1)\n",
    "X = df_proc.drop(['sl_no','id','Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "X,Y=X.to_numpy(),Y.to_numpy()\n",
    "X,Y=X.T,Y.reshape(1, Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n",
    "\n",
    "#split data to X train Xtest Y train Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking all 9 layers as input\n",
    "in_layer_no=X.shape[0] #no of attributes\n",
    "hid_layer_no=int(1.5*in_layer_no)\n",
    "out_layer_no=1\n",
    "\n",
    "#initial weights\n",
    "wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "initial_weights=[wh,bh,w_out,b_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "13\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 9)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(in_layer_no)\n",
    "print(hid_layer_no)\n",
    "print(out_layer_no)\n",
    "wh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(X,Y,learning_rate,initial_weights):\n",
    "    wh=initial_weights[0]\n",
    "    bh=initial_weights[1]\n",
    "    w_out=initial_weights[2]\n",
    "    b_out=initial_weights[3]\n",
    "    dwh_old=0\n",
    "    dw_out_old=0\n",
    "    for i in range(0,100000):\n",
    "        #forward propogation\n",
    "        #input to hidden layer = dot product(X,wh) + bh\n",
    "        hid_layer_input = np.dot(wh,X) + bh\n",
    "        hid_layer_act = relu(hid_layer_input)\n",
    "        \n",
    "        # Final output layer prediction\n",
    "        out_layer_input = np.dot(w_out,hid_layer_act) + b_out\n",
    "        out_layer_act = sigmoid(out_layer_input)\n",
    "        lo=loss(out_layer_act,Y)\n",
    "        if(i%1000==0):\n",
    "            print(i,lo)\n",
    "        '''dZ2 = out_layer_act - Y\n",
    "        dW2 = (1 /X.shape[1]) * np.dot(dZ2, hid_layer_act.T)\n",
    "        db2 = (1 / X.shape[1]) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.multiply(np.dot(w_out.T, dZ2), 1 - np.power(hid_layer_act, 2))\n",
    "        dW1 = (1 / X.shape[1]) * np.dot(dZ1, X.T)\n",
    "        db1 = (1 / X.shape[1]) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dW1\n",
    "        w_out = w_out - learning_rate * dW2\n",
    "        bh = bh - learning_rate * db1\n",
    "        b_out = b_out - learning_rate * db2\n",
    "        '''\n",
    "        #backward propogation output layer    \n",
    "        t_o = out_layer_act - Y\n",
    "        sigmak = t_o * sigmoid(out_layer_input)*(1-sigmoid(out_layer_input))   \n",
    "        dLoss_W2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak,hid_layer_act.T)\n",
    "        dLoss_b2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak, np.ones([sigmak.shape[1],1])) \n",
    "          \n",
    "        #backward propogation input layer\n",
    "        dLoss_A1 = np.dot(w_out.T,sigmak)\n",
    "        dLoss_Z1 = dLoss_A1 * drelu(hid_layer_input)        \n",
    "        dLoss_A0 = np.dot(wh.T,dLoss_Z1)\n",
    "        dLoss_W1 = 1/X.shape[1] * np.dot(dLoss_Z1,X.T)\n",
    "        dLoss_b1 = 1/X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n",
    "        \n",
    "        wh = wh - learning_rate * dLoss_W1\n",
    "        w_out = w_out - learning_rate * dLoss_W2\n",
    "        bh = bh - learning_rate * dLoss_b1\n",
    "        b_out = b_out - learning_rate * dLoss_b2\n",
    "    return [wh,bh,w_out,b_out]\n",
    "    ''' \n",
    "        #backpropogation\n",
    "        dout_layer_act = (out_layer_act - Y) / (out_layer_act * (1 - out_layer_act))\n",
    "        dZ2 = np.multiply(dout_layer_act, out_layer_act * (1 - out_layer_act))\n",
    "        dw_out = np.dot(dZ2, hid_layer_act.T)\n",
    "        #dw_out=dw_out+0.5*dw_out_old\n",
    "        #dw_out_old=dw_out\n",
    "        db_out = np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dhid_layer_act = np.dot(w_out.T, dZ2)\n",
    "        dZ1 = np.multiply(dhid_layer_act, dhid_layer_act * (1 - dhid_layer_act))\n",
    "        dwh = np.dot(dZ1, X.T)\n",
    "        #dwh=dwh+0.2*dwh_old\n",
    "        #dwh_old=dwh\n",
    "        dbh = np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dwh\n",
    "        w_out = w_out - learning_rate * dw_out\n",
    "        bh = bh - learning_rate * dbh\n",
    "        b_out = b_out - learning_rate * db_out\n",
    "    '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6998187948987924\n",
      "1000 0.6377822950995017\n",
      "2000 0.6215885807945587\n",
      "3000 0.5423958611897002\n",
      "4000 0.18946447788995283\n",
      "5000 0.13442865781959734\n",
      "6000 0.11786630856428194\n",
      "7000 0.1098364973919441\n",
      "8000 0.10503059148697583\n",
      "9000 0.10184046164545175\n",
      "10000 0.09961649967791852\n",
      "11000 0.09795551890258615\n",
      "12000 0.09664494375198177\n",
      "13000 0.09564070525165196\n",
      "14000 0.09483033610268977\n",
      "15000 0.09419691926507162\n",
      "16000 0.09369897434410251\n",
      "17000 0.09321480540548353\n",
      "18000 0.09281324563995698\n",
      "19000 0.09253856960964775\n",
      "20000 0.09225075271428093\n",
      "21000 0.09188651401502948\n",
      "22000 0.09165593095456272\n",
      "23000 0.0914879316766189\n",
      "24000 0.09138470112713933\n",
      "25000 0.09127740272246132\n",
      "26000 0.09118781572941913\n",
      "27000 0.09111187727778429\n",
      "28000 0.0910435129800273\n",
      "29000 0.09097496641396154\n",
      "30000 0.09093066903963969\n",
      "31000 0.0908979979318542\n",
      "32000 0.09087444311791383\n",
      "33000 0.09085544691235385\n",
      "34000 0.09083881046897463\n",
      "35000 0.09082332454456817\n",
      "36000 0.09081046531741925\n",
      "37000 0.09079245116856845\n",
      "38000 0.09077873364685288\n",
      "39000 0.09077015270643982\n",
      "40000 0.09077277534942937\n",
      "41000 0.09077738347116282\n",
      "42000 0.09078956879627098\n",
      "43000 0.09080461378759239\n",
      "44000 0.09082152220450089\n",
      "45000 0.09083914999780941\n",
      "46000 0.0908581020354271\n",
      "47000 0.09087889529766631\n",
      "48000 0.09090009121429593\n",
      "49000 0.09092252322132034\n",
      "50000 0.09094584139838802\n",
      "51000 0.09096830947785718\n",
      "52000 0.09099041680756663\n",
      "53000 0.09101242493422865\n",
      "54000 0.09103582093846783\n",
      "55000 0.09106107736902772\n",
      "56000 0.0910817874729434\n",
      "57000 0.09110090210418112\n",
      "58000 0.09112188344581858\n",
      "59000 0.09114121231997624\n",
      "60000 0.09115973794559562\n",
      "61000 0.09117776431935821\n",
      "62000 0.0911960733220612\n",
      "63000 0.09121440578516059\n",
      "64000 0.09123295076386567\n",
      "65000 0.09125195622590318\n",
      "66000 0.09127035852313795\n",
      "67000 0.0912890101858333\n",
      "68000 0.09130668607436192\n",
      "69000 0.09136276771081182\n",
      "70000 0.09137188212197071\n",
      "71000 0.09144150535381733\n",
      "72000 0.09138518461387411\n",
      "73000 0.09125894803248394\n",
      "74000 0.09118257610624576\n",
      "75000 0.09115340565207818\n",
      "76000 0.09114346549859662\n",
      "77000 0.09115441129134179\n",
      "78000 0.09117977974236723\n",
      "79000 0.09104586925338845\n",
      "80000 0.09101510064834657\n",
      "81000 0.09098744985144629\n",
      "82000 0.09097778343399056\n",
      "83000 0.09097905081735\n",
      "84000 0.09098524418721635\n",
      "85000 0.09097739968059797\n",
      "86000 0.09095574880398515\n",
      "87000 0.09094983960995744\n",
      "88000 0.0909476467628676\n",
      "89000 0.09094036487318773\n",
      "90000 0.09092743962274202\n",
      "91000 0.09091708837032998\n",
      "92000 0.09090598000427047\n",
      "93000 0.09089474614381311\n",
      "94000 0.09088315833623413\n",
      "95000 0.0908711418955263\n",
      "96000 0.0908574054651435\n",
      "97000 0.09084446821251897\n",
      "98000 0.0908358266610622\n",
      "99000 0.09082594630532816\n"
     ]
    }
   ],
   "source": [
    "#here replace X with X train and Y with Y train\n",
    "final_weights=ann(X,Y,0.05,initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final backpropogation to test training data \n",
    "hid_layer_input = np.dot(final_weights[0],X) + final_weights[1]\n",
    "hid_layer_act = relu(hid_layer_input)\n",
    "out_layer_input = np.dot(final_weights[2],hid_layer_act) + final_weights[3]\n",
    "out_layer_act = sigmoid(out_layer_input)\n",
    "predictions = out_layer_act > 0.5\n",
    "predictions=predictions.astype(int)  \n",
    "\n",
    "#here replace the X with X test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97%\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')\n",
    "#replace Y with Y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
