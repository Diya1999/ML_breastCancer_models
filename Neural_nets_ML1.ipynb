{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_k(x,k):\n",
    "    return 1 / (1 + k*np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_layer_act\n",
    "def drelu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(out,Y):\n",
    "        loss = (-1)*(np.sum(np.multiply(np.log(out), Y) + np.multiply((1 - Y), np.log(1 - out))))/(Y.shape[1])\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testimg relu and sigmoid\n",
    "#relu(5)\n",
    "#relu(-3)\n",
    "#relu(0)\n",
    "\n",
    "#sigmoid(5)\n",
    "#sigmoid(0)\n",
    "#sigmoid(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = pd.read_csv(\"preprocessed.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.columns=[\"sl_no\",\"id\",\"thickness\", \"cellsize\", \"cellshape\", \"madhesion\", \"secellsize\", \"barenuclei\", \"chromatin\", \"nucleoli\", \"mitosis\",\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_proc.filter(['Class'], axis=1)\n",
    "X = df_proc.drop(['sl_no','id','Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699) (9, 559) (1, 559) (9, 140) (1, 140)\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "XTrain,XTest,YTrain,YTest=train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X,Y=X.to_numpy(),Y.to_numpy()\n",
    "XTrain,XTest,YTrain,YTest= XTrain.to_numpy().T,XTest.to_numpy().T,YTrain.to_numpy().reshape(1, YTrain.shape[0]),YTest.to_numpy().reshape(1, YTest.shape[0])\n",
    "X,Y=X.T,Y.reshape(1, Y.shape[0])\n",
    "\n",
    "print(X.shape,Y.shape,XTrain.shape,YTrain.shape,XTest.shape,YTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 699) (1, 699)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking all 9 layers as input\n",
    "in_layer_no=X.shape[0] #no of attributes\n",
    "hid_layer_no=int(1.5*in_layer_no)\n",
    "out_layer_no=1\n",
    "\n",
    "#initial weights\n",
    "wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "initial_weights=[wh,bh,w_out,b_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "13\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(in_layer_no)\n",
    "print(hid_layer_no)\n",
    "print(out_layer_no)\n",
    "wh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(X,Y,learning_rate):\n",
    "    #taking all 9 layers as input\n",
    "    in_layer_no=X.shape[0] #no of attributes\n",
    "    hid_layer_no=int(1.5*in_layer_no)\n",
    "    out_layer_no=1\n",
    "\n",
    "    #initial weights\n",
    "    wh = np.random.randn(hid_layer_no,in_layer_no) * 0.01\n",
    "    bh = np.zeros(shape=(hid_layer_no, 1))\n",
    "    w_out = np.random.randn(out_layer_no,hid_layer_no) * 0.01\n",
    "    b_out = np.zeros(shape=(out_layer_no, 1))\n",
    "\n",
    "    initial_weights=[wh,bh,w_out,b_out]\n",
    "    dwh_old=0\n",
    "    dw_out_old=0\n",
    "    for i in range(0,100000):\n",
    "        #forward propogation\n",
    "        #input to hidden layer = dot product(X,wh) + bh\n",
    "        hid_layer_input = np.dot(wh,X) + bh\n",
    "        hid_layer_act = relu(hid_layer_input)\n",
    "        \n",
    "        # Final output layer prediction\n",
    "        out_layer_input = np.dot(w_out,hid_layer_act) + b_out\n",
    "        out_layer_act = sigmoid(out_layer_input)\n",
    "        lo=loss(out_layer_act,Y)\n",
    "        if(i%1000==0):\n",
    "            print(i,lo)\n",
    "        '''dZ2 = out_layer_act - Y\n",
    "        dW2 = (1 /X.shape[1]) * np.dot(dZ2, hid_layer_act.T)\n",
    "        db2 = (1 / X.shape[1]) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.multiply(np.dot(w_out.T, dZ2), 1 - np.power(hid_layer_act, 2))\n",
    "        dW1 = (1 / X.shape[1]) * np.dot(dZ1, X.T)\n",
    "        db1 = (1 / X.shape[1]) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dW1\n",
    "        w_out = w_out - learning_rate * dW2\n",
    "        bh = bh - learning_rate * db1\n",
    "        b_out = b_out - learning_rate * db2\n",
    "        '''\n",
    "        #backward propogation output layer    \n",
    "        t_o = out_layer_act - Y\n",
    "        sigmak = t_o * sigmoid(out_layer_input)*(1-sigmoid(out_layer_input))   \n",
    "        dLoss_W2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak,hid_layer_act.T)\n",
    "        dLoss_b2 = (1/hid_layer_act.shape[1]) * np.dot(sigmak, np.ones([sigmak.shape[1],1])) \n",
    "          \n",
    "        #backward propogation input layer\n",
    "        dLoss_A1 = np.dot(w_out.T,sigmak)\n",
    "        dLoss_Z1 = dLoss_A1 * drelu(hid_layer_input)        \n",
    "        dLoss_A0 = np.dot(wh.T,dLoss_Z1)\n",
    "        dLoss_W1 = 1/X.shape[1] * np.dot(dLoss_Z1,X.T)\n",
    "        dLoss_b1 = 1/X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n",
    "        \n",
    "        wh = wh - learning_rate * dLoss_W1\n",
    "        w_out = w_out - learning_rate * dLoss_W2\n",
    "        bh = bh - learning_rate * dLoss_b1\n",
    "        b_out = b_out - learning_rate * dLoss_b2\n",
    "    return [wh,bh,w_out,b_out]\n",
    "    ''' \n",
    "        #backpropogation\n",
    "        dout_layer_act = (out_layer_act - Y) / (out_layer_act * (1 - out_layer_act))\n",
    "        dZ2 = np.multiply(dout_layer_act, out_layer_act * (1 - out_layer_act))\n",
    "        dw_out = np.dot(dZ2, hid_layer_act.T)\n",
    "        #dw_out=dw_out+0.5*dw_out_old\n",
    "        #dw_out_old=dw_out\n",
    "        db_out = np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dhid_layer_act = np.dot(w_out.T, dZ2)\n",
    "        dZ1 = np.multiply(dhid_layer_act, dhid_layer_act * (1 - dhid_layer_act))\n",
    "        dwh = np.dot(dZ1, X.T)\n",
    "        #dwh=dwh+0.2*dwh_old\n",
    "        #dwh_old=dwh\n",
    "        dbh = np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        wh = wh - learning_rate * dwh\n",
    "        w_out = w_out - learning_rate * dw_out\n",
    "        bh = bh - learning_rate * dbh\n",
    "        b_out = b_out - learning_rate * db_out\n",
    "    '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final forward propogation to test trained model \n",
    "def predict(XTrain,YTrain,XTest,YTest,learning_rate):\n",
    "    final_weights=ann(XTrain,YTrain,learning_rate)\n",
    "    hid_layer_input = np.dot(final_weights[0],XTest) + final_weights[1]\n",
    "    hid_layer_act = relu(hid_layer_input)\n",
    "    out_layer_input = np.dot(final_weights[2],hid_layer_act) + final_weights[3]\n",
    "    out_layer_act = sigmoid(out_layer_input)\n",
    "    predictions = out_layer_act > 0.5\n",
    "    predictions=predictions.astype(int)  \n",
    "    accuracy=float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100)\n",
    "    #print(accuracy)\n",
    "    #print ('Accuracy: %f' % float((np.dot(YTest,predictions.T) + np.dot(1-YTest,1-predictions.T))/float(YTest.size)*100) + '%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6926638704708253\n",
      "1000 0.6406218949126709\n",
      "2000 0.6125360233751603\n",
      "3000 0.3385779414334623\n",
      "4000 0.1589472218533854\n",
      "5000 0.1281541058323269\n",
      "6000 0.11604351905194145\n",
      "7000 0.10969276836540792\n",
      "8000 0.10534936326862686\n",
      "9000 0.10228024785504498\n",
      "10000 0.10004864072079588\n",
      "11000 0.09836706491114577\n",
      "12000 0.09712558490450607\n",
      "13000 0.09600335873343768\n",
      "14000 0.09485658413243268\n",
      "15000 0.09388672780162068\n",
      "16000 0.09305552278462662\n",
      "17000 0.09241967566895268\n",
      "18000 0.09195482434008488\n",
      "19000 0.0914442823233655\n",
      "20000 0.09105855321028265\n",
      "21000 0.090658380594726\n",
      "22000 0.09035278713024973\n",
      "23000 0.09007100161142013\n",
      "24000 0.08975703528767097\n",
      "25000 0.08952882933753066\n",
      "26000 0.08932377804915873\n",
      "27000 0.08913697941202751\n",
      "28000 0.08896508156294022\n",
      "29000 0.08880641298964542\n",
      "30000 0.08866004404631557\n",
      "31000 0.08852365551160735\n",
      "32000 0.08839732399195968\n",
      "33000 0.0882775455132749\n",
      "34000 0.08816640073666823\n",
      "35000 0.08806050576984151\n",
      "36000 0.08796070637826994\n",
      "37000 0.08786773135637978\n",
      "38000 0.08777980582173484\n",
      "39000 0.0876945285560425\n",
      "40000 0.0876126997304094\n",
      "41000 0.08755827750332584\n",
      "42000 0.08741331197310513\n",
      "43000 0.08731760124466582\n",
      "44000 0.08722909747657229\n",
      "45000 0.08714610967523265\n",
      "46000 0.08707339196235066\n",
      "47000 0.08700154622015614\n",
      "48000 0.08693466280347376\n",
      "49000 0.0868714600920008\n",
      "50000 0.08681163848652247\n",
      "51000 0.08675531593630034\n",
      "52000 0.08670143820324472\n",
      "53000 0.08665006481895597\n",
      "54000 0.08660120043395086\n",
      "55000 0.08655382467998032\n",
      "56000 0.08650863695412528\n",
      "57000 0.0864647287942694\n",
      "58000 0.08642232932474182\n",
      "59000 0.08638198724355786\n",
      "60000 0.08634286526079162\n",
      "61000 0.08630671563739263\n",
      "62000 0.08627200191661155\n",
      "63000 0.08623670291768318\n",
      "64000 0.08620098414973669\n",
      "65000 0.08616666065957446\n",
      "66000 0.08614703716796017\n",
      "67000 0.08610656462287442\n",
      "68000 0.08605835789646817\n",
      "69000 0.08603868030651998\n",
      "70000 0.08599962051607846\n",
      "71000 0.08596776170411663\n",
      "72000 0.08593239108172479\n",
      "73000 0.08589770199354091\n",
      "74000 0.08586029106097567\n",
      "75000 0.08582064683196555\n",
      "76000 0.08578522086387959\n",
      "77000 0.08574957039991168\n",
      "78000 0.0857154104089496\n",
      "79000 0.08568238066166003\n",
      "80000 0.08565109814413244\n",
      "81000 0.08562045350900988\n",
      "82000 0.08558836235492581\n",
      "83000 0.08555700151200843\n",
      "84000 0.08552629551652495\n",
      "85000 0.08549562264417283\n",
      "86000 0.08546640920770393\n",
      "87000 0.08543821596333949\n",
      "88000 0.08541074467021977\n",
      "89000 0.08538427704435612\n",
      "90000 0.08535859412615142\n",
      "91000 0.08533384281365884\n",
      "92000 0.08530944399803171\n",
      "93000 0.08528590907794653\n",
      "94000 0.0852625035063825\n",
      "95000 0.08523995079140004\n",
      "96000 0.08521799372087274\n",
      "97000 0.08519675549991332\n",
      "98000 0.08517602327017433\n",
      "99000 0.0851551635113509\n"
     ]
    }
   ],
   "source": [
    "acc=predict(XTrain,YTrain,XTest,YTest,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.14285714285714\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
